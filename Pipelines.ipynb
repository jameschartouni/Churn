{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import RobustScaler, PolynomialFeatures, StandardScaler, MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"cleaned_input/train_consolidated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504818, 122)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "data = data.drop([\"msno\", \"Unnamed: 0\"], axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trans_count                    False\n",
       "date_min                       False\n",
       "date_max                       False\n",
       "date_count                     False\n",
       "num_25_sum                     False\n",
       "num_50_sum                     False\n",
       "num_75_sum                     False\n",
       "num_985_sum                    False\n",
       "num_100_sum                    False\n",
       "num_unq_sum                    False\n",
       "total_secs_sum                 False\n",
       "city                           False\n",
       "bd                             False\n",
       "registered_via                 False\n",
       "registration_init_year         False\n",
       "registration_init_month        False\n",
       "registration_init_date         False\n",
       "payment_method_id              False\n",
       "payment_plan_days              False\n",
       "plan_list_price                False\n",
       "actual_amount_paid             False\n",
       "is_auto_renew                  False\n",
       "is_cancel                      False\n",
       "discount                       False\n",
       "is_discount                    False\n",
       "amt_per_day                    False\n",
       "membership_duration            False\n",
       "membership_duration_M          False\n",
       "notAutorenew_&_cancel          False\n",
       "price_paid/duration            False\n",
       "                               ...  \n",
       "payment_method_id_encoded12    False\n",
       "payment_method_id_encoded13    False\n",
       "payment_method_id_encoded14    False\n",
       "payment_method_id_encoded15    False\n",
       "payment_method_id_encoded16    False\n",
       "payment_method_id_encoded17    False\n",
       "payment_method_id_encoded18    False\n",
       "payment_method_id_encoded19    False\n",
       "payment_method_id_encoded20    False\n",
       "payment_method_id_encoded21    False\n",
       "payment_method_id_encoded22    False\n",
       "payment_method_id_encoded23    False\n",
       "payment_method_id_encoded24    False\n",
       "payment_method_id_encoded25    False\n",
       "payment_method_id_encoded26    False\n",
       "payment_method_id_encoded27    False\n",
       "payment_method_id_encoded28    False\n",
       "payment_method_id_encoded29    False\n",
       "payment_method_id_encoded30    False\n",
       "payment_method_id_encoded31    False\n",
       "payment_method_id_encoded32    False\n",
       "payment_method_id_encoded33    False\n",
       "payment_method_id_encoded34    False\n",
       "payment_method_id_encoded35    False\n",
       "is_auto_renew_encoded0         False\n",
       "is_auto_renew_encoded1         False\n",
       "is_auto_renew_encoded2         False\n",
       "is_cancel_encoded0             False\n",
       "is_cancel_encoded1             False\n",
       "is_cancel_encoded2             False\n",
       "Length: 121, dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data = data.sample(frac=.1)\n",
    "X_train = model_data.drop(['is_churn'], axis=1);\n",
    "y_train = model_data['is_churn'];\n",
    "X_train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(est, X_train, y_train):\n",
    "    train_size, train_score, CV_score = learning_curve(est, X_train, y_train, scoring=\"neg_log_loss\", train_sizes=np.linspace(0.1,1, 5));\n",
    "    plt.figure();\n",
    "    plt.plot(train_size, np.mean(train_score, axis=1), 'o-', color='b', label='training score');\n",
    "    plt.plot(train_size, np.mean(CV_score, axis=1), 'o-', color='r', label='CV score');\n",
    "    plt.xlabel(\"Training examples\");\n",
    "    plt.ylabel(\"Score\");\n",
    "    plt.fill_between(train_size, np.mean(train_score, axis=1) - np.std(train_score, axis=1),\n",
    "                     np.mean(train_score, axis=1) + np.std(train_score, axis=1), alpha=0.1,\n",
    "                     color=\"b\");\n",
    "    plt.fill_between(train_size, np.mean(CV_score, axis=1) - np.std(CV_score, axis=1),\n",
    "                     np.mean(CV_score, axis=1) + np.std(CV_score, axis=1), alpha=0.1,\n",
    "                     color=\"r\");\n",
    "    plt.title(\"Learning Curve\", fontsize=20);\n",
    "    plt.legend();\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### making list of parameters for grid search\n",
    "param_logit = {'C':[0.01,0.1,1,10,100], 'penalty':['l1','l2']}\n",
    "param_svc = {'C':[0.01,0.1,1,10,100], 'kernel':{'rbf','sigmoid','precomputed'}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/James/anaconda/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x106f19270, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/James/anaconda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/James/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/James.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x106f19270, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/James/anaconda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/James/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/James.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...t(CV.best_score_)    \\nprint(CV.best_params_)    \\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 9, 10, 54, 46, 955534), 'msg_id': '736E1718986A4B228E993BF877370C9C', 'msg_type': 'execute_request', 'session': '5F488383EF4F4621879ABF2C90159D95', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '736E1718986A4B228E993BF877370C9C', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'5F488383EF4F4621879ABF2C90159D95']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...t(CV.best_score_)    \\nprint(CV.best_params_)    \\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 9, 10, 54, 46, 955534), 'msg_id': '736E1718986A4B228E993BF877370C9C', 'msg_type': 'execute_request', 'session': '5F488383EF4F4621879ABF2C90159D95', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '736E1718986A4B228E993BF877370C9C', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'5F488383EF4F4621879ABF2C90159D95'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...t(CV.best_score_)    \\nprint(CV.best_params_)    \\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 9, 10, 54, 46, 955534), 'msg_id': '736E1718986A4B228E993BF877370C9C', 'msg_type': 'execute_request', 'session': '5F488383EF4F4621879ABF2C90159D95', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '736E1718986A4B228E993BF877370C9C', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...t(CV.best_score_)    \\nprint(CV.best_params_)    \\n\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...t(CV.best_score_)    \\nprint(CV.best_params_)    \\n\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...t(CV.best_score_)    \\nprint(CV.best_params_)    \\n\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...t(CV.best_score_)    \\nprint(CV.best_params_)    \\n\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...t(CV.best_score_)    \\nprint(CV.best_params_)    \\n\", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-18-546b6e76a55a>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1a1305a240, execution..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1a13065930, file \"<ipython-input-18-546b6e76a55a>\", line 17>\n        result = <ExecutionResult object at 1a1305a240, execution..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1a13065930, file \"<ipython-input-18-546b6e76a55a>\", line 17>, result=<ExecutionResult object at 1a1305a240, execution..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1a13065930, file \"<ipython-input-18-546b6e76a55a>\", line 17>\n        self.user_global_ns = {'CV': GridSearchCV(cv=None, error_score='raise',\n     ...'warn',\n       scoring='neg_log_loss', verbose=0), 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import numpy as np # linear algebra\\nimport panda....read_csv(\"cleaned_input/train_consolidated.csv\")', 'import numpy as np # linear algebra\\nimport panda...ession\\nfrom sklearn.pipeline import make_pipeline', 'data = pd.read_csv(\"cleaned_input/train_consolidated.csv\")', 'data.head()\\ndata = data.drop([\"msno\", \"Unnamed: 0\"], axis=1)\\ndata.shape', \"model_data = data.sample(frac=.1)\\nX_train = mode... = model_data['is_churn'];\\nX_train.isnull().any()\", 'def plot_learning_curve(est, X_train, y_train):\\n..., fontsize=20);\\n    plt.legend();\\n    plt.show();', \"#### making list of parameters for grid search\\np...0,100], 'kernel':{'rbf','sigmoid','precomputed'}}\", \"lgbm_pipeline = Pipeline([('lgbm', LGBMRegressor())])\", 'import numpy as np # linear algebra\\nimport panda...ession\\nfrom sklearn.pipeline import make_pipeline', \"lgbm_pipeline = Pipeline([('lgbm', LGBMRegressor())])\", 'import numpy as np # linear algebra\\nimport panda...m sklearn.pipeline import make_pipeline, pipeline', 'import numpy as np # linear algebra\\nimport panda...m sklearn.pipeline import make_pipeline, Pipeline', \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifier())])\", 'import numpy as np # linear algebra\\nimport panda... PolynomialFeatures, StandardScaler, MinMaxScaler', \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...tion set: %s' % (round(MAE(y_valid, y_pred), 5)))\", \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...tion set: %s' % (round(MAE(y_valid, y_pred), 5)))\", \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...nt(CV.best_score_)    \\nprint(CV.best_params_)    \", \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...nt(CV.best_score_)    \\nprint(CV.best_params_)    \"], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {4: (504818, 122), 5: trans_count                    False\ndate_min   ...coded2             False\nLength: 121, dtype: bool}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'PolynomialFeatures': <class 'sklearn.preprocessing.data.PolynomialFeatures'>, 'RobustScaler': <class 'sklearn.preprocessing.data.RobustScaler'>, ...}\n        self.user_ns = {'CV': GridSearchCV(cv=None, error_score='raise',\n     ...'warn',\n       scoring='neg_log_loss', verbose=0), 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import numpy as np # linear algebra\\nimport panda....read_csv(\"cleaned_input/train_consolidated.csv\")', 'import numpy as np # linear algebra\\nimport panda...ession\\nfrom sklearn.pipeline import make_pipeline', 'data = pd.read_csv(\"cleaned_input/train_consolidated.csv\")', 'data.head()\\ndata = data.drop([\"msno\", \"Unnamed: 0\"], axis=1)\\ndata.shape', \"model_data = data.sample(frac=.1)\\nX_train = mode... = model_data['is_churn'];\\nX_train.isnull().any()\", 'def plot_learning_curve(est, X_train, y_train):\\n..., fontsize=20);\\n    plt.legend();\\n    plt.show();', \"#### making list of parameters for grid search\\np...0,100], 'kernel':{'rbf','sigmoid','precomputed'}}\", \"lgbm_pipeline = Pipeline([('lgbm', LGBMRegressor())])\", 'import numpy as np # linear algebra\\nimport panda...ession\\nfrom sklearn.pipeline import make_pipeline', \"lgbm_pipeline = Pipeline([('lgbm', LGBMRegressor())])\", 'import numpy as np # linear algebra\\nimport panda...m sklearn.pipeline import make_pipeline, pipeline', 'import numpy as np # linear algebra\\nimport panda...m sklearn.pipeline import make_pipeline, Pipeline', \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifier())])\", 'import numpy as np # linear algebra\\nimport panda... PolynomialFeatures, StandardScaler, MinMaxScaler', \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...tion set: %s' % (round(MAE(y_valid, y_pred), 5)))\", \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...tion set: %s' % (round(MAE(y_valid, y_pred), 5)))\", \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...nt(CV.best_score_)    \\nprint(CV.best_params_)    \", \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...nt(CV.best_score_)    \\nprint(CV.best_params_)    \"], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {4: (504818, 122), 5: trans_count                    False\ndate_min   ...coded2             False\nLength: 121, dtype: bool}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'PolynomialFeatures': <class 'sklearn.preprocessing.data.PolynomialFeatures'>, 'RobustScaler': <class 'sklearn.preprocessing.data.RobustScaler'>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/Users/James/Kaggle Competitions/WSDM - KKBox's Churn Prediction Challenge/Churn/<ipython-input-18-546b6e76a55a> in <module>()\n     12     'reg_alpha' : [1,1.2],\n     13     'reg_lambda' : [1,1.2,1.4],\n     14     }\n     15 \n     16 CV = GridSearchCV(lgbm_pipeline, parameters, scoring = 'neg_log_loss', n_jobs= 3)\n---> 17 CV.fit(X_train, y_train)   \n     18 \n     19 print('Best score and parameter combination = ')\n     20 \n     21 print(CV.best_score_)    \n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...'warn',\n       scoring='neg_log_loss', verbose=0), X=        trans_count    date_min    date_max  dat...                  0  \n\n[50482 rows x 121 columns], y=278339    0\n132288    0\n140354    0\n70120     0\n...    0\nName: is_churn, Length: 50482, dtype: int64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X =         trans_count    date_min    date_max  dat...                  0  \n\n[50482 rows x 121 columns]\n        y = 278339    0\n132288    0\n140354    0\n70120     0\n...    0\nName: is_churn, Length: 50482, dtype: int64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=3), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=3)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Dec  9 10:54:47 2017\nPID: 8364                    Python 3.6.0: /Users/James/anaconda/bin/python\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]),         trans_count    date_min    date_max  dat...                  0  \n\n[50482 rows x 121 columns], 278339    0\n132288    0\n140354    0\n70120     0\n...    0\nName: is_churn, Length: 50482, dtype: int64, {'score': make_scorer(log_loss, greater_is_better=False, needs_proba=True)}, array([16816, 16817, 16818, ..., 50479, 50480, 50481]), array([    0,     1,     2, ..., 16976, 16981, 16987]), 0, {'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]),         trans_count    date_min    date_max  dat...                  0  \n\n[50482 rows x 121 columns], 278339    0\n132288    0\n140354    0\n70120     0\n...    0\nName: is_churn, Length: 50482, dtype: int64, {'score': make_scorer(log_loss, greater_is_better=False, needs_proba=True)}, array([16816, 16817, 16818, ..., 50479, 50480, 50481]), array([    0,     1,     2, ..., 16976, 16981, 16987]), 0, {'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]), X=        trans_count    date_min    date_max  dat...                  0  \n\n[50482 rows x 121 columns], y=278339    0\n132288    0\n140354    0\n70120     0\n...    0\nName: is_churn, Length: 50482, dtype: int64, scorer={'score': make_scorer(log_loss, greater_is_better=False, needs_proba=True)}, train=array([16816, 16817, 16818, ..., 50479, 50480, 50481]), test=array([    0,     1,     2, ..., 16976, 16981, 16987]), verbose=0, parameters={'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...mple_for_bin=50000,\n        subsample_freq=1))])>\n        parameters = {'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]), **kwargs={'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...mple_for_bin=50000,\n        subsample_freq=1))])>\n        kwargs = {'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]), attr='steps', **params={'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...mple_for_bin=50000,\n        subsample_freq=1))])>\n        params = {'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]), **params={'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'boosting_type'\n        self = Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))])\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter boosting_type for estimator Pipeline(memory=None,\n     steps=[('lgbm', LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, learning_rate=0.1,\n        max_bin=255, max_depth=-1, min_child_samples=10,\n        min_child_weight=5, min_split_gain=0, n_estimators=10, nthread=-1,\n        num_leaves=31, objective='binary', reg_alpha=0, reg_lambda=0,\n        seed=0, silent=True, subsample=1, subsample_for_bin=50000,\n        subsample_freq=1))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/James/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/James/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/James/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/James/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 444, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"/Users/James/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py\", line 142, in set_params\n    self._set_params('steps', **kwargs)\n  File \"/Users/James/anaconda/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\", line 49, in _set_params\n    super(_BaseComposition, self).set_params(**params)\n  File \"/Users/James/anaconda/lib/python3.6/site-packages/sklearn/base.py\", line 274, in set_params\n    (key, self))\nValueError: Invalid parameter boosting_type for estimator Pipeline(memory=None,\n     steps=[('lgbm', LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, learning_rate=0.1,\n        max_bin=255, max_depth=-1, min_child_samples=10,\n        min_child_weight=5, min_split_gain=0, n_estimators=10, nthread=-1,\n        num_leaves=31, objective='binary', reg_alpha=0, reg_lambda=0,\n        seed=0, silent=True, subsample=1, subsample_for_bin=50000,\n        subsample_freq=1))]). Check the list of available parameters with `estimator.get_params().keys()`.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/James/anaconda/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/James/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Sat Dec  9 10:54:47 2017\nPID: 8364                    Python 3.6.0: /Users/James/anaconda/bin/python\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]),         trans_count    date_min    date_max  dat...                  0  \n\n[50482 rows x 121 columns], 278339    0\n132288    0\n140354    0\n70120     0\n...    0\nName: is_churn, Length: 50482, dtype: int64, {'score': make_scorer(log_loss, greater_is_better=False, needs_proba=True)}, array([16816, 16817, 16818, ..., 50479, 50480, 50481]), array([    0,     1,     2, ..., 16976, 16981, 16987]), 0, {'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]),         trans_count    date_min    date_max  dat...                  0  \n\n[50482 rows x 121 columns], 278339    0\n132288    0\n140354    0\n70120     0\n...    0\nName: is_churn, Length: 50482, dtype: int64, {'score': make_scorer(log_loss, greater_is_better=False, needs_proba=True)}, array([16816, 16817, 16818, ..., 50479, 50480, 50481]), array([    0,     1,     2, ..., 16976, 16981, 16987]), 0, {'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]), X=        trans_count    date_min    date_max  dat...                  0  \n\n[50482 rows x 121 columns], y=278339    0\n132288    0\n140354    0\n70120     0\n...    0\nName: is_churn, Length: 50482, dtype: int64, scorer={'score': make_scorer(log_loss, greater_is_better=False, needs_proba=True)}, train=array([16816, 16817, 16818, ..., 50479, 50480, 50481]), test=array([    0,     1,     2, ..., 16976, 16981, 16987]), verbose=0, parameters={'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...mple_for_bin=50000,\n        subsample_freq=1))])>\n        parameters = {'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]), **kwargs={'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...mple_for_bin=50000,\n        subsample_freq=1))])>\n        kwargs = {'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]), attr='steps', **params={'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...mple_for_bin=50000,\n        subsample_freq=1))])>\n        params = {'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]), **params={'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'boosting_type'\n        self = Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))])\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter boosting_type for estimator Pipeline(memory=None,\n     steps=[('lgbm', LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, learning_rate=0.1,\n        max_bin=255, max_depth=-1, min_child_samples=10,\n        min_child_weight=5, min_split_gain=0, n_estimators=10, nthread=-1,\n        num_leaves=31, objective='binary', reg_alpha=0, reg_lambda=0,\n        seed=0, silent=True, subsample=1, subsample_for_bin=50000,\n        subsample_freq=1))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/Users/James/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/James/anaconda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Sat Dec  9 10:54:47 2017\nPID: 8364                    Python 3.6.0: /Users/James/anaconda/bin/python\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]),         trans_count    date_min    date_max  dat...                  0  \n\n[50482 rows x 121 columns], 278339    0\n132288    0\n140354    0\n70120     0\n...    0\nName: is_churn, Length: 50482, dtype: int64, {'score': make_scorer(log_loss, greater_is_better=False, needs_proba=True)}, array([16816, 16817, 16818, ..., 50479, 50480, 50481]), array([    0,     1,     2, ..., 16976, 16981, 16987]), 0, {'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]),         trans_count    date_min    date_max  dat...                  0  \n\n[50482 rows x 121 columns], 278339    0\n132288    0\n140354    0\n70120     0\n...    0\nName: is_churn, Length: 50482, dtype: int64, {'score': make_scorer(log_loss, greater_is_better=False, needs_proba=True)}, array([16816, 16817, 16818, ..., 50479, 50480, 50481]), array([    0,     1,     2, ..., 16976, 16981, 16987]), 0, {'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]), X=        trans_count    date_min    date_max  dat...                  0  \n\n[50482 rows x 121 columns], y=278339    0\n132288    0\n140354    0\n70120     0\n...    0\nName: is_churn, Length: 50482, dtype: int64, scorer={'score': make_scorer(log_loss, greater_is_better=False, needs_proba=True)}, train=array([16816, 16817, 16818, ..., 50479, 50480, 50481]), test=array([    0,     1,     2, ..., 16976, 16981, 16987]), verbose=0, parameters={'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...mple_for_bin=50000,\n        subsample_freq=1))])>\n        parameters = {'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]), **kwargs={'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...mple_for_bin=50000,\n        subsample_freq=1))])>\n        kwargs = {'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]), attr='steps', **params={'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...mple_for_bin=50000,\n        subsample_freq=1))])>\n        params = {'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]), **params={'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'boosting_type'\n        self = Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))])\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter boosting_type for estimator Pipeline(memory=None,\n     steps=[('lgbm', LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, learning_rate=0.1,\n        max_bin=255, max_depth=-1, min_child_samples=10,\n        min_child_weight=5, min_split_gain=0, n_estimators=10, nthread=-1,\n        num_leaves=31, objective='binary', reg_alpha=0, reg_lambda=0,\n        seed=0, silent=True, subsample=1, subsample_for_bin=50000,\n        subsample_freq=1))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-546b6e76a55a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mCV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgbm_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'neg_log_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mCV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best score and parameter combination = '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/James/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/James/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/James/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/James/anaconda/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x106f19270, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/James/anaconda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/James/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/James.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x106f19270, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/James/anaconda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/James/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/James.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...t(CV.best_score_)    \\nprint(CV.best_params_)    \\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 9, 10, 54, 46, 955534), 'msg_id': '736E1718986A4B228E993BF877370C9C', 'msg_type': 'execute_request', 'session': '5F488383EF4F4621879ABF2C90159D95', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '736E1718986A4B228E993BF877370C9C', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'5F488383EF4F4621879ABF2C90159D95']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...t(CV.best_score_)    \\nprint(CV.best_params_)    \\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 9, 10, 54, 46, 955534), 'msg_id': '736E1718986A4B228E993BF877370C9C', 'msg_type': 'execute_request', 'session': '5F488383EF4F4621879ABF2C90159D95', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '736E1718986A4B228E993BF877370C9C', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'5F488383EF4F4621879ABF2C90159D95'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...t(CV.best_score_)    \\nprint(CV.best_params_)    \\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 9, 10, 54, 46, 955534), 'msg_id': '736E1718986A4B228E993BF877370C9C', 'msg_type': 'execute_request', 'session': '5F488383EF4F4621879ABF2C90159D95', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '736E1718986A4B228E993BF877370C9C', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...t(CV.best_score_)    \\nprint(CV.best_params_)    \\n\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...t(CV.best_score_)    \\nprint(CV.best_params_)    \\n\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...t(CV.best_score_)    \\nprint(CV.best_params_)    \\n\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...t(CV.best_score_)    \\nprint(CV.best_params_)    \\n\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...t(CV.best_score_)    \\nprint(CV.best_params_)    \\n\", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-18-546b6e76a55a>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1a1305a240, execution..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1a13065930, file \"<ipython-input-18-546b6e76a55a>\", line 17>\n        result = <ExecutionResult object at 1a1305a240, execution..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1a13065930, file \"<ipython-input-18-546b6e76a55a>\", line 17>, result=<ExecutionResult object at 1a1305a240, execution..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1a13065930, file \"<ipython-input-18-546b6e76a55a>\", line 17>\n        self.user_global_ns = {'CV': GridSearchCV(cv=None, error_score='raise',\n     ...'warn',\n       scoring='neg_log_loss', verbose=0), 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import numpy as np # linear algebra\\nimport panda....read_csv(\"cleaned_input/train_consolidated.csv\")', 'import numpy as np # linear algebra\\nimport panda...ession\\nfrom sklearn.pipeline import make_pipeline', 'data = pd.read_csv(\"cleaned_input/train_consolidated.csv\")', 'data.head()\\ndata = data.drop([\"msno\", \"Unnamed: 0\"], axis=1)\\ndata.shape', \"model_data = data.sample(frac=.1)\\nX_train = mode... = model_data['is_churn'];\\nX_train.isnull().any()\", 'def plot_learning_curve(est, X_train, y_train):\\n..., fontsize=20);\\n    plt.legend();\\n    plt.show();', \"#### making list of parameters for grid search\\np...0,100], 'kernel':{'rbf','sigmoid','precomputed'}}\", \"lgbm_pipeline = Pipeline([('lgbm', LGBMRegressor())])\", 'import numpy as np # linear algebra\\nimport panda...ession\\nfrom sklearn.pipeline import make_pipeline', \"lgbm_pipeline = Pipeline([('lgbm', LGBMRegressor())])\", 'import numpy as np # linear algebra\\nimport panda...m sklearn.pipeline import make_pipeline, pipeline', 'import numpy as np # linear algebra\\nimport panda...m sklearn.pipeline import make_pipeline, Pipeline', \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifier())])\", 'import numpy as np # linear algebra\\nimport panda... PolynomialFeatures, StandardScaler, MinMaxScaler', \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...tion set: %s' % (round(MAE(y_valid, y_pred), 5)))\", \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...tion set: %s' % (round(MAE(y_valid, y_pred), 5)))\", \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...nt(CV.best_score_)    \\nprint(CV.best_params_)    \", \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...nt(CV.best_score_)    \\nprint(CV.best_params_)    \"], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {4: (504818, 122), 5: trans_count                    False\ndate_min   ...coded2             False\nLength: 121, dtype: bool}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'PolynomialFeatures': <class 'sklearn.preprocessing.data.PolynomialFeatures'>, 'RobustScaler': <class 'sklearn.preprocessing.data.RobustScaler'>, ...}\n        self.user_ns = {'CV': GridSearchCV(cv=None, error_score='raise',\n     ...'warn',\n       scoring='neg_log_loss', verbose=0), 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import numpy as np # linear algebra\\nimport panda....read_csv(\"cleaned_input/train_consolidated.csv\")', 'import numpy as np # linear algebra\\nimport panda...ession\\nfrom sklearn.pipeline import make_pipeline', 'data = pd.read_csv(\"cleaned_input/train_consolidated.csv\")', 'data.head()\\ndata = data.drop([\"msno\", \"Unnamed: 0\"], axis=1)\\ndata.shape', \"model_data = data.sample(frac=.1)\\nX_train = mode... = model_data['is_churn'];\\nX_train.isnull().any()\", 'def plot_learning_curve(est, X_train, y_train):\\n..., fontsize=20);\\n    plt.legend();\\n    plt.show();', \"#### making list of parameters for grid search\\np...0,100], 'kernel':{'rbf','sigmoid','precomputed'}}\", \"lgbm_pipeline = Pipeline([('lgbm', LGBMRegressor())])\", 'import numpy as np # linear algebra\\nimport panda...ession\\nfrom sklearn.pipeline import make_pipeline', \"lgbm_pipeline = Pipeline([('lgbm', LGBMRegressor())])\", 'import numpy as np # linear algebra\\nimport panda...m sklearn.pipeline import make_pipeline, pipeline', 'import numpy as np # linear algebra\\nimport panda...m sklearn.pipeline import make_pipeline, Pipeline', \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifier())])\", 'import numpy as np # linear algebra\\nimport panda... PolynomialFeatures, StandardScaler, MinMaxScaler', \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...tion set: %s' % (round(MAE(y_valid, y_pred), 5)))\", \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...tion set: %s' % (round(MAE(y_valid, y_pred), 5)))\", \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...nt(CV.best_score_)    \\nprint(CV.best_params_)    \", \"lgbm_pipeline = Pipeline([('lgbm', LGBMClassifie...nt(CV.best_score_)    \\nprint(CV.best_params_)    \"], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {4: (504818, 122), 5: trans_count                    False\ndate_min   ...coded2             False\nLength: 121, dtype: bool}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'PolynomialFeatures': <class 'sklearn.preprocessing.data.PolynomialFeatures'>, 'RobustScaler': <class 'sklearn.preprocessing.data.RobustScaler'>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/Users/James/Kaggle Competitions/WSDM - KKBox's Churn Prediction Challenge/Churn/<ipython-input-18-546b6e76a55a> in <module>()\n     12     'reg_alpha' : [1,1.2],\n     13     'reg_lambda' : [1,1.2,1.4],\n     14     }\n     15 \n     16 CV = GridSearchCV(lgbm_pipeline, parameters, scoring = 'neg_log_loss', n_jobs= 3)\n---> 17 CV.fit(X_train, y_train)   \n     18 \n     19 print('Best score and parameter combination = ')\n     20 \n     21 print(CV.best_score_)    \n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...'warn',\n       scoring='neg_log_loss', verbose=0), X=        trans_count    date_min    date_max  dat...                  0  \n\n[50482 rows x 121 columns], y=278339    0\n132288    0\n140354    0\n70120     0\n...    0\nName: is_churn, Length: 50482, dtype: int64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X =         trans_count    date_min    date_max  dat...                  0  \n\n[50482 rows x 121 columns]\n        y = 278339    0\n132288    0\n140354    0\n70120     0\n...    0\nName: is_churn, Length: 50482, dtype: int64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=3), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=3)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Dec  9 10:54:47 2017\nPID: 8364                    Python 3.6.0: /Users/James/anaconda/bin/python\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]),         trans_count    date_min    date_max  dat...                  0  \n\n[50482 rows x 121 columns], 278339    0\n132288    0\n140354    0\n70120     0\n...    0\nName: is_churn, Length: 50482, dtype: int64, {'score': make_scorer(log_loss, greater_is_better=False, needs_proba=True)}, array([16816, 16817, 16818, ..., 50479, 50480, 50481]), array([    0,     1,     2, ..., 16976, 16981, 16987]), 0, {'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]),         trans_count    date_min    date_max  dat...                  0  \n\n[50482 rows x 121 columns], 278339    0\n132288    0\n140354    0\n70120     0\n...    0\nName: is_churn, Length: 50482, dtype: int64, {'score': make_scorer(log_loss, greater_is_better=False, needs_proba=True)}, array([16816, 16817, 16818, ..., 50479, 50480, 50481]), array([    0,     1,     2, ..., 16976, 16981, 16987]), 0, {'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]), X=        trans_count    date_min    date_max  dat...                  0  \n\n[50482 rows x 121 columns], y=278339    0\n132288    0\n140354    0\n70120     0\n...    0\nName: is_churn, Length: 50482, dtype: int64, scorer={'score': make_scorer(log_loss, greater_is_better=False, needs_proba=True)}, train=array([16816, 16817, 16818, ..., 50479, 50480, 50481]), test=array([    0,     1,     2, ..., 16976, 16981, 16987]), verbose=0, parameters={'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...mple_for_bin=50000,\n        subsample_freq=1))])>\n        parameters = {'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]), **kwargs={'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...mple_for_bin=50000,\n        subsample_freq=1))])>\n        kwargs = {'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]), attr='steps', **params={'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...mple_for_bin=50000,\n        subsample_freq=1))])>\n        params = {'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/Users/James/anaconda/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))]), **params={'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'boosting_type'\n        self = Pipeline(memory=None,\n     steps=[('lgbm', LGBMC...ample_for_bin=50000,\n        subsample_freq=1))])\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter boosting_type for estimator Pipeline(memory=None,\n     steps=[('lgbm', LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, learning_rate=0.1,\n        max_bin=255, max_depth=-1, min_child_samples=10,\n        min_child_weight=5, min_split_gain=0, n_estimators=10, nthread=-1,\n        num_leaves=31, objective='binary', reg_alpha=0, reg_lambda=0,\n        seed=0, silent=True, subsample=1, subsample_for_bin=50000,\n        subsample_freq=1))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "lgbm_pipeline = Pipeline([('lgbm', LGBMClassifier())])\n",
    "\n",
    "parameters = {\n",
    "    'learning_rate': [0.005],\n",
    "    'n_estimators': [8,16,24],\n",
    "    'num_leaves': [6,8,12,16],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'random_state' : [501], # Updated from 'seed'\n",
    "    'colsample_bytree' : [0.64, 0.65, 0.66],\n",
    "    'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2],\n",
    "    'reg_lambda' : [1,1.2,1.4],\n",
    "    }\n",
    "\n",
    "CV = GridSearchCV(lgbm_pipeline, parameters, scoring = 'neg_log_loss', n_jobs= 3)\n",
    "CV.fit(X_train, y_train)   \n",
    "\n",
    "print('Best score and parameter combination = ')\n",
    "\n",
    "print(CV.best_score_)    \n",
    "print(CV.best_params_)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "   params = {'boosting_type': 'gbdt',\n",
    "          'max_depth' : -1,\n",
    "          'objective': 'binary', \n",
    "          'nthread': 3, # Updated from nthread\n",
    "          'num_leaves': 64, \n",
    "          'learning_rate': 0.05, \n",
    "          'max_bin': 512, \n",
    "          'subsample_for_bin': 200,\n",
    "          'subsample': 1, \n",
    "          'subsample_freq': 1, \n",
    "          'colsample_bytree': 0.8, \n",
    "          'reg_alpha': 5, \n",
    "          'reg_lambda': 10,\n",
    "          'min_split_gain': 0.5, \n",
    "          'min_child_weight': 1, \n",
    "          'min_child_samples': 5, \n",
    "          'scale_pos_weight': 1,\n",
    "          'num_class' : 1,\n",
    "          'metric' : 'binary_error'}\n",
    "\n",
    "# Create parameters to search\n",
    "gridParams = {\n",
    "    'learning_rate': [0.005],\n",
    "    'n_estimators': [8,16,24],\n",
    "    'num_leaves': [6,8,12,16],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'random_state' : [501], # Updated from 'seed'\n",
    "    'colsample_bytree' : [0.64, 0.65, 0.66],\n",
    "    'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2],\n",
    "    'reg_lambda' : [1,1.2,1.4],\n",
    "    }\n",
    "\n",
    "# Create classifier to use. Note that parameters have to be input manually\n",
    "# not as a dict!\n",
    "mdl = lgb.LGBMClassifier(boosting_type= 'gbdt', \n",
    "          objective = 'binary', \n",
    "          n_jobs = 5, # Updated from 'nthread' \n",
    "          silent = True,\n",
    "          max_depth = params['max_depth'],\n",
    "          max_bin = params['max_bin'], \n",
    "          subsample_for_bin = params['subsample_for_bin'],\n",
    "          subsample = params['subsample'], \n",
    "          subsample_freq = params['subsample_freq'], \n",
    "          min_split_gain = params['min_split_gain'], \n",
    "          min_child_weight = params['min_child_weight'], \n",
    "          min_child_samples = params['min_child_samples'], \n",
    "          scale_pos_weight = params['scale_pos_weight'])\n",
    "\n",
    "# To view the default model params:\n",
    "mdl.get_params().keys()\n",
    "\n",
    "# Create the grid\n",
    "grid = GridSearchCV(mdl, gridParams, verbose=1, cv=4, n_jobs=-1)\n",
    "# Run the grid\n",
    "grid.fit(allTrainData, allTrainLabels)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
