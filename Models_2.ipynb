{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#james chartouni\n",
        "import lightgbm as lgb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import inf\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = pd.read_csv(\"cleaned_input/train_consolidated.csv\")\n",
        "training_data = training_data.drop(['msno'], axis=1)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split data \n",
        "y = training_data[\"is_churn\"].values\n",
        "X = training_data.drop([\"is_churn\"], axis=1).values\n",
        "#remove infinite values? \n",
        "X[X == -inf] = 0\n",
        "X[X == inf] = 0\n",
        "\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.15, shuffle=True)#change to stratified shuffle split"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#logistic regression \n",
        "\n",
        "logistic_pipe = make_pipeline(LogisticRegression())\n",
        "scores = cross_val_score(logistic_pipe, X_train, y_train, cv=5, scoring=\"neg_log_loss\")\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Light GBM \n",
        "# create dataset for lightgbm\n",
        "# if you want to re-use data, remember to set free_raw_data=False\n",
        "lgb_train = lgb.Dataset(X_train, y_train, free_raw_data=False)\n",
        "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train,free_raw_data=False)\n",
        "\n",
        "# specify your configurations as a dict\n",
        "params = {\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'binary',\n",
        "    'metric': 'binary_logloss',\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.9,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'verbose': 0\n",
        "}\n",
        "\n",
        "# generate a feature name\n",
        "feature_name = X_train.dtype.names\n",
        "\n",
        "print('Start training...')\n",
        "# feature_name and categorical_feature\n",
        "gbm = lgb.train(params,\n",
        "                lgb_train,\n",
        "                num_boost_round=50,\n",
        "                valid_sets=lgb_train,  # eval training data\n",
        "              )\n",
        "\n",
        "# save model to file\n",
        "gbm.save_model('model.txt')\n",
        "\n",
        "# feature names\n",
        "print('Feature names:', gbm.feature_name())\n",
        "\n",
        "# feature importances\n",
        "print('Feature importances:', list(gbm.feature_importance()))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "[1]\ttraining's binary_logloss: 0.644421\n",
            "[2]\ttraining's binary_logloss: 0.600332\n",
            "[3]\ttraining's binary_logloss: 0.560244\n",
            "[4]\ttraining's binary_logloss: 0.523647\n",
            "[5]\ttraining's binary_logloss: 0.490118\n",
            "[6]\ttraining's binary_logloss: 0.459299\n",
            "[7]\ttraining's binary_logloss: 0.433141\n",
            "[8]\ttraining's binary_logloss: 0.408971\n",
            "[9]\ttraining's binary_logloss: 0.384348\n",
            "[10]\ttraining's binary_logloss: 0.361511\n",
            "[11]\ttraining's binary_logloss: 0.340291\n",
            "[12]\ttraining's binary_logloss: 0.320542\n",
            "[13]\ttraining's binary_logloss: 0.302131\n",
            "[14]\ttraining's binary_logloss: 0.284948\n",
            "[15]\ttraining's binary_logloss: 0.268888\n",
            "[16]\ttraining's binary_logloss: 0.25386\n",
            "[17]\ttraining's binary_logloss: 0.239787\n",
            "[18]\ttraining's binary_logloss: 0.226588\n",
            "[19]\ttraining's binary_logloss: 0.214203\n",
            "[20]\ttraining's binary_logloss: 0.202571\n",
            "[21]\ttraining's binary_logloss: 0.191637\n",
            "[22]\ttraining's binary_logloss: 0.181352\n",
            "[23]\ttraining's binary_logloss: 0.171672\n",
            "[24]\ttraining's binary_logloss: 0.162554\n",
            "[25]\ttraining's binary_logloss: 0.153963\n",
            "[26]\ttraining's binary_logloss: 0.145861\n",
            "[27]\ttraining's binary_logloss: 0.138218\n",
            "[28]\ttraining's binary_logloss: 0.131004\n",
            "[29]\ttraining's binary_logloss: 0.124194\n",
            "[30]\ttraining's binary_logloss: 0.11776\n",
            "[31]\ttraining's binary_logloss: 0.111679\n",
            "[32]\ttraining's binary_logloss: 0.105932\n",
            "[33]\ttraining's binary_logloss: 0.100496\n",
            "[34]\ttraining's binary_logloss: 0.0958485\n",
            "[35]\ttraining's binary_logloss: 0.0909564\n",
            "[36]\ttraining's binary_logloss: 0.0863257\n",
            "[37]\ttraining's binary_logloss: 0.0819406\n",
            "[38]\ttraining's binary_logloss: 0.0777879\n",
            "[39]\ttraining's binary_logloss: 0.0738552\n",
            "[40]\ttraining's binary_logloss: 0.0701299\n",
            "[41]\ttraining's binary_logloss: 0.0665993\n",
            "[42]\ttraining's binary_logloss: 0.0632525\n",
            "[43]\ttraining's binary_logloss: 0.0600798\n",
            "[44]\ttraining's binary_logloss: 0.0570714\n",
            "[45]\ttraining's binary_logloss: 0.0542192\n",
            "[46]\ttraining's binary_logloss: 0.0515138\n",
            "[47]\ttraining's binary_logloss: 0.0489475\n",
            "[48]\ttraining's binary_logloss: 0.0465119\n",
            "[49]\ttraining's binary_logloss: 0.044201\n",
            "[50]\ttraining's binary_logloss: 0.0420083\n",
            "Feature names: ['Column_0', 'Column_1', 'Column_2', 'Column_3', 'Column_4', 'Column_5', 'Column_6', 'Column_7', 'Column_8', 'Column_9', 'Column_10', 'Column_11', 'Column_12', 'Column_13', 'Column_14', 'Column_15', 'Column_16', 'Column_17', 'Column_18', 'Column_19', 'Column_20', 'Column_21', 'Column_22', 'Column_23', 'Column_24', 'Column_25', 'Column_26', 'Column_27', 'Column_28', 'Column_29', 'Column_30', 'Column_31', 'Column_32', 'Column_33', 'Column_34', 'Column_35', 'Column_36', 'Column_37', 'Column_38', 'Column_39', 'Column_40', 'Column_41']\n",
            "Feature importances: [94, 103, 92, 56, 62, 27, 36, 49, 24, 156, 38, 1, 17, 4, 63, 23, 15, 7, 21, 39, 20, 26, 0, 0, 32, 98, 26, 101, 17, 46, 3, 72, 0, 4, 5, 6, 27, 4, 31, 27, 14, 14]\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.3.4"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}