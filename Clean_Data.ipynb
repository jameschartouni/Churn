{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#James Chartouni\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import gc; gc.enable()\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transactions\n",
      "(992931, 3)\n",
      "transaction merge...\n",
      "user_logs\n",
      "(992931, 3)\n",
      "(6338005, 11)\n",
      "members\n",
      "members merge...\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('raw_data/train.csv')\n",
    "test = pd.read_csv('raw_data/sample_submission_zero.csv')\n",
    "\n",
    "print(\"transactions\")\n",
    "transactions = pd.read_csv('cleaned_input/transactions.csv', usecols=['msno'], dtype={\"msno\":str})\n",
    "transactions = pd.DataFrame(transactions['msno'].value_counts().reset_index())\n",
    "transactions.columns = ['msno','trans_count']\n",
    "train = pd.merge(train, transactions, how='left', on='msno')\n",
    "print(train.shape)\n",
    "test = pd.merge(test, transactions, how='left', on='msno')\n",
    "transactions = []; print('transaction merge...')\n",
    "\n",
    "print(\"user_logs\")\n",
    "user_logs = pd.read_csv(\"cleaned_input/processed_user_log.csv\")\n",
    "user_logs_2 = pd.read_csv(\"cleaned_input/processed_user_log_v2.csv\")\n",
    "user_logs = pd.concat((user_logs, user_logs_2))\n",
    "\n",
    "'''user_logs = pd.read_csv('raw_data/user_logs.csv', usecols=['msno'])\n",
    "user_logs_2 = pd.read_csv('raw_data/user_logs_v2.csv', usecols=['msno'])\n",
    "user_logs = pd.concat((user_logs, user_logs_2))\n",
    "user_logs = pd.DataFrame(user_logs['msno'].value_counts().reset_index())\n",
    "#user_logs.to_csv('cleaned_input/user_logs_merged.csv')\n",
    "user_logs_reduced = user_logs\n",
    "user_logs_reduced.columns = ['msno','logs_count']'''\n",
    "\n",
    "print(train.shape)\n",
    "print(user_logs.shape)\n",
    "train = pd.merge(train, user_logs, how='left', on='msno')\n",
    "test = pd.merge(test, user_logs, how='left', on='msno')\n",
    "user_logs_reduced = []\n",
    "\n",
    "print(\"members\")\n",
    "members = pd.read_csv('cleaned_input/members.csv')\n",
    "train = pd.merge(train, members, how='left', on='msno')\n",
    "test = pd.merge(test, members, how='left', on='msno')\n",
    "members = []; print('members merge...') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#combine user_log_time_series\n",
    "user_log_time_series = pd.read_csv(\"100_user_logs_features.csv\")\n",
    "user_log_time_series_1 = pd.read_csv(\"100_user_logs_features.csv\")\n",
    "user_log_time_series_2 = pd.read_csv(\"200_user_logs_features.csv\")\n",
    "user_log_time_series_3 = pd.read_csv(\"300_user_logs_features.csv\")\n",
    "user_log_time_series_4 = pd.read_csv(\"400_user_logs_features.csv\")\n",
    "user_log_time_series_5 = pd.read_csv(\"500_user_logs_features.csv\")\n",
    "user_log_time_series_6 = pd.read_csv(\"600_user_logs_features.csv\")\n",
    "user_log_time_series_7 = pd.read_csv(\"5100_user_logs_features_3.csv\")\n",
    "user_log_time_series_8 = pd.read_csv(\"5200_user_logs_features_3.csv\")\n",
    "user_log_time_series_9 = pd.read_csv(\"5300_user_logs_features_3.csv\")\n",
    "\n",
    "user_log_time_series.append(user_log_time_series_1)\n",
    "user_log_time_series.append(user_log_time_series_2)\n",
    "user_log_time_series.append(user_log_time_series_3)\n",
    "user_log_time_series.append(user_log_time_series_4)\n",
    "user_log_time_series.append(user_log_time_series_5)\n",
    "user_log_time_series.append(user_log_time_series_6)\n",
    "user_log_time_series.append(user_log_time_series_7)\n",
    "user_log_time_series.append(user_log_time_series_8)\n",
    "user_log_time_series.append(user_log_time_series_9)\n",
    "\n",
    "user_log_time_series = user_log_time_series.drop(user_log_time_series.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>gap_days</th>\n",
       "      <th>average_gap_days</th>\n",
       "      <th>longest_gap</th>\n",
       "      <th>gaps_longer_29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yxiEWwE9VR5utpUecLxVdQ5B7NysUPfrNtGINaM2zA8=</td>\n",
       "      <td>732</td>\n",
       "      <td>5.270400e+06</td>\n",
       "      <td>7430400.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PNxIsSLWOJDCm7pNPFzRO/6Mmg2WeZA2nf6hw6t1x3g=</td>\n",
       "      <td>402</td>\n",
       "      <td>1.736640e+07</td>\n",
       "      <td>18144000.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KXF9c/T66LZIzFq+xS64icWMhDQE6miCZAtdXRjZHX8=</td>\n",
       "      <td>532</td>\n",
       "      <td>1.532160e+07</td>\n",
       "      <td>25747200.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OcZ3fKQzHrL1BuzuFRzUiwPr8l9P8JKCFpafdYf5sCY=</td>\n",
       "      <td>689</td>\n",
       "      <td>5.411782e+06</td>\n",
       "      <td>6652800.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dW5DQO92XaG024D2QYmktyUnLc2axil74zUPAhF8sEs=</td>\n",
       "      <td>673</td>\n",
       "      <td>5.814720e+06</td>\n",
       "      <td>10627200.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno gap_days  average_gap_days  \\\n",
       "0  yxiEWwE9VR5utpUecLxVdQ5B7NysUPfrNtGINaM2zA8=      732      5.270400e+06   \n",
       "1  PNxIsSLWOJDCm7pNPFzRO/6Mmg2WeZA2nf6hw6t1x3g=      402      1.736640e+07   \n",
       "2  KXF9c/T66LZIzFq+xS64icWMhDQE6miCZAtdXRjZHX8=      532      1.532160e+07   \n",
       "3  OcZ3fKQzHrL1BuzuFRzUiwPr8l9P8JKCFpafdYf5sCY=      689      5.411782e+06   \n",
       "4  dW5DQO92XaG024D2QYmktyUnLc2axil74zUPAhF8sEs=      673      5.814720e+06   \n",
       "\n",
       "   longest_gap  gaps_longer_29  \n",
       "0    7430400.0            12.0  \n",
       "1   18144000.0             2.0  \n",
       "2   25747200.0             3.0  \n",
       "3    6652800.0            11.0  \n",
       "4   10627200.0            10.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user_log_time_series = pd.to_numeric(user_log_time_series[user_log_time_series.columns[1]])\n",
    "user_log_time_series[\"gap_days\"] = user_log_time_series[\"gap_days\"].astype(str).str.split().str[0].str.rsplit('.').str[0]\n",
    "user_log_time_series.head()\n",
    "#.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_log_time_series.to_csv(\"cleaned_input/user_log_time_series.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1731290, 22)\n",
      "(6338005, 11)\n",
      "(131992, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(user_logs.shape)\n",
    "print(user_log_time_series.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "transactions = pd.read_csv('raw_data/transactions.csv')\n",
    "transactions = transactions.sort_values(by=['transaction_date'], ascending=[False]).reset_index(drop=True)\n",
    "transactions = transactions.drop_duplicates(subset=['msno'], keep='first')\n",
    "\n",
    "train = pd.merge(train, transactions, how='left', on='msno')\n",
    "test = pd.merge(test, transactions, how='left', on='msno')\n",
    "transactions=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['msno', 'is_churn', 'trans_count', 'date_min', 'date_max', 'date_count',\n",
       "       'num_25_sum', 'num_50_sum', 'num_75_sum', 'num_985_sum', 'num_100_sum',\n",
       "       'num_unq_sum', 'total_secs_sum', 'Unnamed: 0', 'city', 'bd', 'gender',\n",
       "       'registered_via', 'registration_init_time', 'registration_init_year',\n",
       "       'registration_init_month', 'registration_init_date',\n",
       "       'payment_method_id', 'payment_plan_days', 'plan_list_price',\n",
       "       'actual_amount_paid', 'is_auto_renew', 'transaction_date',\n",
       "       'membership_expire_date', 'is_cancel'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000000, 9)\n",
      "... (1616917, 9)\n",
      "(10000000, 9)\n",
      "... (1533539, 9)\n",
      "(10000000, 9)\n",
      "... (1353720, 9)\n",
      "(2106543, 9)\n",
      "... (429234, 9)\n"
     ]
    }
   ],
   "source": [
    "def transform_df(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    df = df.sort_values(by=['date'], ascending=[False])\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.drop_duplicates(subset=['msno'], keep='first')\n",
    "    return df\n",
    "\n",
    "def transform_df2(df):\n",
    "    df = df.sort_values(by=['date'], ascending=[False])\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.drop_duplicates(subset=['msno'], keep='first')\n",
    "    return df\n",
    "\n",
    "#make sure you add user_logs_2\n",
    "df_iter = pd.read_csv('raw_data/user_logs.csv', low_memory=False, iterator=True, chunksize=10000000)\n",
    "last_user_logs = []\n",
    "i = 0 #~400 Million Records - starting at the end but remove locally if needed\n",
    "for df in df_iter:\n",
    "    if i>35:\n",
    "        if len(df)>0:\n",
    "            print(df.shape)\n",
    "            p = Pool(cpu_count())\n",
    "            df = p.map(transform_df, np.array_split(df, cpu_count()))   \n",
    "            df = pd.concat(df, axis=0, ignore_index=True).reset_index(drop=True)\n",
    "            df = transform_df2(df)\n",
    "            p.close(); p.join()\n",
    "            last_user_logs.append(df)\n",
    "            print('...', df.shape)\n",
    "            df = []\n",
    "    i+=1\n",
    "\n",
    "last_user_logs = pd.concat(last_user_logs, axis=0, ignore_index=True).reset_index(drop=True)\n",
    "last_user_logs = transform_df2(last_user_logs)\n",
    "\n",
    "train = pd.merge(train, last_user_logs, how='left', on='msno')\n",
    "test = pd.merge(test, last_user_logs, how='left', on='msno')\n",
    "last_user_logs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#if missing >3 cells, remove row \n",
    "train = train.dropna(thresh=3)\n",
    "test = test.dropna(thresh=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove outliers\n",
    "train = train.drop(train[train.bd < 7].index)\n",
    "train = train.drop(train[train.bd > 99].index)\n",
    "test = test.drop(test[test.bd < 7].index)\n",
    "test = test.drop(test[test.bd > 99].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(853753, 30)\n",
      "(857110, 30)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "train.to_csv(\"cleaned_input/train_merged.csv\")\n",
    "test.to_csv(\"cleaned_input/test_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#shortcut so don't have to load the first part \n",
    "train = pd.read_csv('cleaned_input/train_merged.csv')\n",
    "test = pd.read_csv(\"cleaned_input/test_merged.csv\")\n",
    "user_logs = pd.read_csv('cleaned_input/user_logs_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "data = pd.concat(( train, test ))\n",
    "train_cutoff = len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "#fill in missing data points and encode variables\n",
    "from helpers import *\n",
    "\n",
    "nan_zero = {\"logs_count\":0}\n",
    "nan_dif = {\"city\":-1, \"registered_via\":-1, \"payment_method_id\":-1, \"is_auto_renew\":-1, \"is_cancel\":-1}\n",
    "nan_med = {\"bd\": 'med', \"registration_init_date\": 'med', \"registration_init_year\":'med', \"registration_init_month\":'med', \n",
    "           \"registration_init_date\":'med', \"registration_init_time\":'med', \"date\":'med', \"num_25\": 'med', \"num_50\": 'med', \"num_75\": 'med', \"num_985\": 'med', \n",
    "           \"num_100\": 'med', \"num_unq\": 'med', \"Unnamed: 0\": 'med', \"total_secs\": 'med', \"trans_count\":'med', 'transaction_date':'med',\n",
    "          'membership_expire_date':'med', 'plan_list_price':'med', 'actual_amount_paid':'med', 'payment_plan_days':'med'}\n",
    "nan_cat = {\"gender\":\"missing\"}\n",
    "\n",
    "data = data.drop([\"Unnamed: 0\", \"gender\"], axis = 0)\n",
    "data = to_fill_na(data, nan_zero)\n",
    "data = to_fill_na(data, nan_dif)\n",
    "data = to_fill_na(data, nan_med)\n",
    "data = to_fill_na(data, nan_cat)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "#feature engineering #DONT FORGET TO REMOVE INFINITE IF DIVIDE BY ZERO\n",
    "\n",
    "data['discount'] = data['plan_list_price'] - data['actual_amount_paid']\n",
    "data['is_discount'] = data.discount.apply(lambda x: 1 if x > 0 else 0)\n",
    "data['amt_per_day'] = data['actual_amount_paid'] / data['payment_plan_days']\n",
    "date_cols = ['transaction_date', 'membership_expire_date']\n",
    "for col in date_cols:\n",
    "    data[col] = pd.to_datetime(data[col], format='%Y%m%d')\n",
    "    \n",
    "#--- difference in days ---\n",
    "data['membership_duration'] = data.membership_expire_date - data.transaction_date\n",
    "data['membership_duration'] = data['membership_duration'] / np.timedelta64(1, 'D')\n",
    "data = to_fill_na(data, {'membership_duration':'med'})\n",
    "data['membership_duration'] = data['membership_duration'].astype(int)\n",
    "\n",
    "#---difference in months ---\n",
    "data['membership_duration_M'] = (data.membership_expire_date - data.transaction_date)/ np.timedelta64(1, 'M')\n",
    "data['membership_duration_M'] = round(data['membership_duration_M']).astype(int)\n",
    "data['membership_duration_M'].head()\n",
    "\n",
    "date_cols = ['registration_init_time']\n",
    "\n",
    "for col in date_cols:\n",
    "    data[col] = pd.to_datetime(data[col], format='%Y%m%d')\n",
    "\n",
    "'''#--- difference in days ---\n",
    "data['registration_duration'] = data.expiration_date - data.registration_init_time\n",
    "data['registration_duration'] = data['registration_duration'] / np.timedelta64(1, 'D')\n",
    "data = to_fill_na(data, {'registration_duration':'med'})\n",
    "data['registration_duration'] = data['registration_duration'].astype(int)'''\n",
    "\n",
    "'''\n",
    "#---difference in months ---\n",
    "data['registration_duration_M'] = (data.expiration_date - data.registration_init_time)/ np.timedelta64(1, 'M')\n",
    "data = to_fill_na(data, {'registration_duration_M':'med'})\n",
    "data['registration_duration_M'] = round(data['registration_duration_M']).astype(int)\n",
    "\n",
    "data['reg_mem_duration'] = data['registration_duration'] - data['membership_duration']\n",
    "to_fill_na(data, {'reg_mem_duration':'med'})\n",
    "data['reg_mem_duration_M'] = data['registration_duration_M'] - data['membership_duration_M']\n",
    "'''\n",
    "data['notAutorenew_&_cancel'] = ((data.is_auto_renew == 0) == (data.is_cancel == 1)).astype(np.int8)\n",
    "data['notAutorenew_&_cancel'].unique()\n",
    "\n",
    "#data['long_time_user'] = (((data['registration_duration'] / 365).astype(int)) > 1).astype(int)\n",
    "\n",
    "#feature ideas to implement\n",
    "#- price paid/ duration \n",
    "data['price_paid/duration'] = data[\"actual_amount_paid\"]/ data[\"membership_duration\"]\n",
    "#- list price/ duration \n",
    "data['list_price/duration'] = data['plan_list_price']/ data[\"membership_duration\"]\n",
    "#- number of unique songs/ price paid\n",
    "data[\"unique_songs/price_paid\"] = data['num_unq']/ data['actual_amount_paid']\n",
    "#- number of unique songs/ list price\n",
    "data[\"unique_songs/list_price\"] = data['num_unq']/ data['plan_list_price']\n",
    "#-num25, num50 etc.../ price paid & list price\n",
    "data[\"num_25/price_paid\"] = data['num_25']/data['actual_amount_paid']\n",
    "data[\"num_50/price_paid\"] = data['num_50']/data['actual_amount_paid']\n",
    "data[\"num_75/price_paid\"] = data['num_75']/data['actual_amount_paid']\n",
    "data[\"num_985/price_paid\"] = data['num_985']/data['actual_amount_paid']\n",
    "data[\"num_100/price_paid\"] = data['num_100']/data['actual_amount_paid']\n",
    "data[\"num_25/list_price\"] = data['num_25']/data['plan_list_price']\n",
    "data[\"num_50/list_price\"] = data['num_50']/data['plan_list_price']\n",
    "data[\"num_75/list_price\"] = data['num_75']/data['plan_list_price']\n",
    "data[\"num_985/list_price\"] = data['num_985']/data['plan_list_price']\n",
    "data[\"num_100/list_price\"] = data['num_100']/data['plan_list_price']\n",
    "# discount percentage (list price - price paid)/ list price \n",
    "data[\"discount_percentage\"] = data['discount']/data['plan_list_price']\n",
    "# days to expiration (expiration date - date)\n",
    "#data['days_to_expiration'] = data['payment_plan_days'] - data['registration_duration']\n",
    "# see if a single user has a pattern of canceling, resubscribing etc...?\n",
    "# could make some really interesting features like how many times did subscribe:?\n",
    "# times canceled ?\n",
    "# Total subscription time  ?\n",
    "# time in between subscriptions? \n",
    "# time in between subscriptions/total subscription time?\n",
    "\n",
    "# try somes features related to age: \n",
    "# price paid/ age \n",
    "data['price_paid/age'] = data['actual_amount_paid']/ data['bd']\n",
    "# unique songs/ age\n",
    "data['unique_song/age'] = data[\"num_unq\"] / data['bd']\n",
    "# discount percentage/ age\n",
    "data['discount_percentage/age'] = data['discount_percentage']/ data['bd']\n",
    "# days to expiration / age \n",
    "#data['days_to_expiration/age'] = data['days_to_expiration'] / data['bd']\n",
    "# age/ date figures \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_logs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#---------user_log stats -----------#\n",
    "#generate the features in a new DF from user_logs and then do a left join with data \n",
    "#how many days\n",
    "    #get unique days\n",
    "    #df['word'].value_counts()\n",
    "rows = data['MSNO'].uniqe()\n",
    "how_many_days = pd.\n",
    "for row in rows:\n",
    "    count = data[row].value_counts() \n",
    "    how_many_days[\"MSNO\", \"days_frequency\"] = [row, count]\n",
    "#how many times canceled\n",
    "#total subscribed days for last subscription \n",
    "#percentage of days streams\n",
    "#check if exists already: total of songs played, total plays\n",
    "#total unique songs/days\n",
    "#total plays/ days\n",
    "#num_25/last day...\n",
    "#relation to time and frequency of plays \n",
    "# time in between subscriptions? \n",
    "# time in between subscriptions/total subscription time?\n",
    "#how many times subscribed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "user_logs = [] \n",
    "\n",
    "#change to dummy variable \n",
    "categorical_to_encode = ['gender']\n",
    "data = label_encoder(data, categorical_to_encode)\n",
    "\n",
    "categorical_to_binarizer = [\"city\", \"gender\", \"registered_via\", \"payment_method_id\", \"is_auto_renew\", \"is_cancel\"]\n",
    "data = label_binarizer(data,categorical_to_binarizer)\n",
    "\n",
    "variables_to_drop = [\"registration_init_time\", \"transaction_date\", \"membership_expire_date\"] \n",
    "data = data.drop(categorical_to_encode, axis=1)\n",
    "data = data.drop(variables_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "train = data[:train_cutoff]\n",
    "test = data[train_cutoff:]\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "train.to_csv(\"cleaned_input/train_consolidated.csv\")\n",
    "test.to_csv(\"cleaned_input/test_consolidated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "nteract": {
   "version": "0.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
